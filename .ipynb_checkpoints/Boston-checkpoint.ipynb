{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  XGBoost stands for \"Extreme Gradient Boosting\" and it is an implementation of gradient boosting machines. The XGBoost is a popular supervised machine learning model with characteristics like fast in computation, parallelization, and better performance. You can find more about the model in this link. In this post, we'll learn how to define the XGBRegressor model and predict regression data in Python.\n",
    "\n",
    "*The tutorial covers:\n",
    "- Preparing data\n",
    "- Defining and fitting the model\n",
    "- Predicting and checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "\n",
    "   We use Boston house-price dataset as regression dataset in this tutorial. After loading the dataset, first, we'll separate data into x - feature and y - label. Then we'll split them into the train and test parts. Here, I'll extract 15 percent of the dataset as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x, y = boston.data, boston.target\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and fitting the model\n",
    "\n",
    "   For the regression problem, we'll use XGBRegressor class of the xgboost package and we can define it with its default parameters. You can also set the new parameter values according to your data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate an XGBoost regressor object \n",
    "xgbr = xgb.XGBRegressor(objective ='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:squarederror',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we'll fit the model with train data.\n",
    "\n",
    "xgbr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting and checking the results\n",
    "\n",
    "\n",
    "After training the model, we'll check the model accuracy with cross-validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation score: 0.85\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(xgbr, xtrain,ytrain,cv=5)\n",
    "print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
    "# Mean cross-validataion score: 0.87 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold CV average score: 0.86\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation with a k-fold method can be checked as a following.\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "kf_cv_scores = cross_val_score(xgbr, xtrain, ytrain, cv=kfold )\n",
    "print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both methods show that the model is around 88 %  accurate on average.\n",
    "Next, we can predict test data and check its accuracy. Here, we'll use MSE and RMSE as accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 9.64\n",
      "RMSE: 3.11\n"
     ]
    }
   ],
   "source": [
    "ypred = xgbr.predict(xtest)\n",
    "mse = mean_squared_error(ytest,ypred)\n",
    "print(\"MSE: %.2f\" % mse)\n",
    "MSE: 3.35\n",
    "print(\"RMSE: %.2f\" % np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, we'll visualize the original and predicted test data in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ax = range(len(ytest))\n",
    "plt.scatter(x_ax, ytest, s=5, color=\"blue\", label=\"original\")\n",
    "plt.plot(x_ax, ypred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
